# 要件定義

## GitHub Issue
https://github.com/k-negishi/ai-curated-newsletter/issues/21

## issue 内容
- タイトル: LLM判定件数を30件から増やす
- 本文: 初期だと何件だっけ？ Bedrockのコストを算出して、候補を複数挙げて、複数の評価軸で評価し推奨度と根拠を教えてください。
- ラベル: なし
- コメント: なし

## 概要

`LLM_CANDIDATE_MAX=30` の実効設定を見直し、Bedrockコストと処理余裕を踏まえた推奨件数へ引き上げる。

## 背景

- 現行ローカル設定（`.env`）では `LLM_CANDIDATE_MAX=30` であり、候補取りこぼしの余地が大きい
- 既存ドキュメントでは「最大150件、推奨120件」の方針が示されている
- ただし実装側のコスト概算は `件数 * 0.01` の仮置きで、根拠が弱い

## コスト算出の前提

- モデル: Claude 3.5 Sonnet v2（`anthropic.claude-3-5-sonnet-20241022-v2:0`）
- 単価（Bedrock）:
  - Input: $6 / 1M tokens
  - Output: $30 / 1M tokens
- 1記事あたり平均トークン（保守的想定）:
  - Input: 900
  - Output: 140
- 実行頻度: 週2回（= 月8回換算）

## 候補案と比較（複数評価軸）

| 候補件数 | 1回あたり推定コスト | 月額推定コスト(8回) | 月$10制約 | カバレッジ | 総合評価 |
|---|---:|---:|---|---|---|
| 60  | $0.58 | $4.61  | 余裕あり | 低め | ○ |
| 90  | $0.86 | $6.91  | 余裕あり | 中 | ◎ |
| 120 | $1.15 | $9.22  | 余裕あり | 高 | ◎（推奨） |
| 150 | $1.44 | $11.52 | 超過      | 最高 | △ |

## 推奨値

- 推奨: `LLM_CANDIDATE_MAX=120`
- 根拠:
  - 月$10制約に収まりつつ、カバレッジを大きく改善
  - ドキュメント上の「推奨120件」と整合
  - 150件はコスト上限を超過しやすく、運用余裕が小さい

## 実装対象

1. Bedrockコスト算出ロジックの明確化
- `src/shared/utils` に推定関数を追加
- Orchestrator の `estimated_cost_usd` を仮置き式から置換

2. LLM判定件数の実効設定変更
- `.env` の `LLM_CANDIDATE_MAX` を `30 -> 120` に更新

3. ドキュメント整合
- `README.md` に推奨値とコスト前提を追記

4. テスト追加
- コスト算出ユーティリティのユニットテスト

## 受け入れ条件

- [x] 30件/60件/90件/120件/150件の推定コストが同一ロジックで算出できる
- [x] `estimated_cost_usd` がトークン単価ベースで算出される
- [x] `.env` の `LLM_CANDIDATE_MAX` が 120 になっている
- [x] 追加テストが通る
- [x] `ruff check src/`, `ruff format src/`, `mypy src/` が成功する

## スコープ外

- Bedrock実課金の実測取得（CloudWatch/Billing API連携）
- モデル切り替え戦略（Sonnet/Haiku動的選択）
- 本番SSM値の直接更新（デプロイスクリプト経由の反映は運用で実施）

## 実装方針
- Kent Beck の TDD (Test-Driven Development) で実装する
- RED → GREEN → REFACTOR のサイクルを遵守
- テストを先に書き、最小限の実装でパスさせ、その後リファクタリング
